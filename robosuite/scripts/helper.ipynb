{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A convenience script to playback random demonstrations from\n",
    "a set of demonstrations stored in a hdf5 file.\n",
    "\n",
    "Arguments:\n",
    "    --folder (str): Path to demonstrations\n",
    "    --use-actions (optional): If this flag is provided, the actions are played back\n",
    "        through the MuJoCo simulator, instead of loading the simulator states\n",
    "        one by one.\n",
    "    --visualize-gripper (optional): If set, will visualize the gripper site\n",
    "\n",
    "Example:\n",
    "    $ python playback_demonstrations_from_hdf5.py --folder ../models/assets/demonstrations/lift/\n",
    "    python playback_demonstrations_from_hdf5.py --folder  /home/ns/robosuite_git/lift_demo\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import robosuite\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--folder\",\n",
    "    type=str,\n",
    "    help=\"Path to your demonstration folder that contains the demo.hdf5 file, e.g.: \"\n",
    "    \"'path_to_assets_dir/demonstrations/YOUR_DEMONSTRATION'\",\n",
    "),\n",
    "parser.add_argument(\n",
    "    \"--use-actions\",\n",
    "    action=\"store_true\",\n",
    ")\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ns/robosuite_git/lift_demo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.folder='/home/ns/robosuite_git/lift_demo'\n",
    "args.folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.use_actions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing back random episode... (press ESC to quit)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'set_camera'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m env\u001b[39m.\u001b[39mreset_from_xml_string(xml)\n\u001b[1;32m     43\u001b[0m env\u001b[39m.\u001b[39msim\u001b[39m.\u001b[39mreset()\n\u001b[0;32m---> 44\u001b[0m env\u001b[39m.\u001b[39;49mviewer\u001b[39m.\u001b[39;49mset_camera(\u001b[39m0\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[39m# load the flattened mujoco states\u001b[39;00m\n\u001b[1;32m     47\u001b[0m states \u001b[39m=\u001b[39m f[\u001b[39m\"\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/states\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(ep)][()]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'set_camera'"
     ]
    }
   ],
   "source": [
    "\n",
    "demo_path = args.folder\n",
    "hdf5_path = os.path.join(demo_path, \"demo.hdf5\")\n",
    "f = h5py.File(hdf5_path, \"r\")\n",
    "env_name = f[\"data\"].attrs[\"env\"]\n",
    "env_info = json.loads(f[\"data\"].attrs[\"env_info\"])\n",
    "\n",
    "# env = robosuite.make(\n",
    "#     **env_info,\n",
    "#     has_renderer=True,\n",
    "#     has_offscreen_renderer=False,\n",
    "#     ignore_done=True,\n",
    "#     use_camera_obs=False,\n",
    "#     reward_shaping=True,\n",
    "#     control_freq=20,\n",
    "# )\n",
    "\n",
    "env = robosuite.make(\n",
    "    **env_info,\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=True,\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=True,\n",
    "    render_camera=\"frontview\",\n",
    "    control_freq=20,\n",
    ")\n",
    "\n",
    "\n",
    "# list of all demonstrations episodes\n",
    "demos = list(f[\"data\"].keys())\n",
    "\n",
    "\n",
    "print(\"Playing back random episode... (press ESC to quit)\")\n",
    "\n",
    "# select an episode randomly\n",
    "ep = random.choice(demos)\n",
    "\n",
    "# read the model xml, using the metadata stored in the attribute for this episode\n",
    "model_xml = f[\"data/{}\".format(ep)].attrs[\"model_file\"]\n",
    "\n",
    "env.reset()\n",
    "xml = env.edit_model_xml(model_xml)\n",
    "env.reset_from_xml_string(xml)\n",
    "env.sim.reset()\n",
    "env.viewer.set_camera(0)\n",
    "\n",
    "# load the flattened mujoco states\n",
    "states = f[\"data/{}/states\".format(ep)][()]\n",
    "\n",
    "if args.use_actions:\n",
    "\n",
    "    # load the initial state\n",
    "    env.sim.set_state_from_flattened(states[0])\n",
    "    env.sim.forward()\n",
    "\n",
    "    # load the actions and play them back open-loop\n",
    "    actions = np.array(f[\"data/{}/actions\".format(ep)][()])\n",
    "    num_actions = actions.shape[0]\n",
    "\n",
    "    for j, action in enumerate(actions):\n",
    "        env.step(action)\n",
    "        env.render()\n",
    "\n",
    "        if j < num_actions - 1:\n",
    "            # ensure that the actions deterministically lead to the same recorded states\n",
    "            state_playback = env.sim.get_state().flatten()\n",
    "            if not np.all(np.equal(states[j + 1], state_playback)):\n",
    "                err = np.linalg.norm(states[j + 1] - state_playback)\n",
    "                print(f\"[warning] playback diverged by {err:.2f} for ep {ep} at step {j}\")\n",
    "\n",
    "else:\n",
    "\n",
    "    # force the sequence of internal mujoco states one by one\n",
    "    for state in states:\n",
    "        env.sim.set_state_from_flattened(state)\n",
    "        env.sim.forward()\n",
    "        env.render()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m frame\u001b[39m=\u001b[39menv\u001b[39m.\u001b[39;49mrender(mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrgb_array\u001b[39;49m\u001b[39m\"\u001b[39;49m, height\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, width\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, camera_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfrontview\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: render() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "frame=env.render(mode=\"rgb_array\", height=512, width=512, camera_name=\"frontview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.use_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = args.folder\n",
    "hdf5_path = os.path.join(demo_path, \"demo.hdf5\")\n",
    "f = h5py.File(hdf5_path, \"r\")\n",
    "env_name = f[\"data\"].attrs[\"env\"]\n",
    "env_info = json.loads(f[\"data\"].attrs[\"env_info\"])\n",
    "\n",
    "# env = robosuite.make(\n",
    "#     **env_info,\n",
    "#     has_renderer=True,\n",
    "#     has_offscreen_renderer=False,\n",
    "#     ignore_done=True,\n",
    "#     use_camera_obs=False,\n",
    "#     reward_shaping=True,\n",
    "#     control_freq=20,\n",
    "#     render_camera=\"frontview\",\n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = robosuite.make(\n",
    "#     \"Lift\",\n",
    "#     robots=\"Sawyer\",\n",
    "#     ignore_done=True,\n",
    "#     use_camera_obs=False,\n",
    "#     has_renderer=True,\n",
    "#     has_offscreen_renderer=False,\n",
    "#     control_freq=20,\n",
    "# )\n",
    "\n",
    "\n",
    "env = robosuite.make(\n",
    "    \"Lift\",\n",
    "    robots=\"Sawyer\",\n",
    "    ignore_done=True,\n",
    "    use_camera_obs=True,\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=True,\n",
    "    render_camera=\"frontview\",\n",
    "    control_freq=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demo_11'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demos = list(f[\"data\"].keys()) \n",
    "ep = random.choice(demos)\n",
    "ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the model xml, using the metadata stored in the attribute for this episode\n",
    "model_xml = f[\"data/{}\".format(ep)].attrs[\"model_file\"]\n",
    "\n",
    "env.reset()\n",
    "xml = env.edit_model_xml(model_xml)\n",
    "env.reset_from_xml_string(xml)\n",
    "env.sim.reset()\n",
    "# env.viewer.set_camera(0)\n",
    "\n",
    "# load the flattened mujoco states\n",
    "states = f[\"data/{}/states\".format(ep)][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array(f[\"data/{}/actions\".format(ep)][()])\n",
    "num_actions = actions.shape[0]\n",
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['robot0_joint_pos_cos', 'robot0_joint_pos_sin', 'robot0_joint_vel', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos', 'robot0_gripper_qvel', 'agentview_image', 'cube_pos', 'cube_quat', 'gripper_to_cube_pos', 'robot0_proprio-state', 'object-state'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the initial state\n",
    "env.sim.set_state_from_flattened(states[0])\n",
    "env.sim.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "environment got invalid action dimension -- expected 8, got 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m action\u001b[39m=\u001b[39mactions[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m env\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/miniconda3/envs/robosuite/lib/python3.8/site-packages/robosuite/environments/base.py:390\u001b[0m, in \u001b[0;36mMujocoEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol_timestep \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_timestep)):\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msim\u001b[39m.\u001b[39mforward()\n\u001b[0;32m--> 390\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pre_action(action, policy_step)\n\u001b[1;32m    391\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    392\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_observables()\n",
      "File \u001b[0;32m~/miniconda3/envs/robosuite/lib/python3.8/site-packages/robosuite/environments/robot_env.py:575\u001b[0m, in \u001b[0;36mRobotEnv._pre_action\u001b[0;34m(self, action, policy_step)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39mOverrides the superclass method to control the robot(s) within this enviornment using their respective\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[39mcontrollers using the passed actions and gripper control.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39m    AssertionError: [Invalid action dimension]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m# Verify that the action is the correct dimension\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(action) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dim, \u001b[39m\"\u001b[39m\u001b[39menvironment got invalid action dimension -- expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    576\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dim, \u001b[39mlen\u001b[39m(action)\n\u001b[1;32m    577\u001b[0m )\n\u001b[1;32m    579\u001b[0m \u001b[39m# Update robot joints based on controller actions\u001b[39;00m\n\u001b[1;32m    580\u001b[0m cutoff \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: environment got invalid action dimension -- expected 8, got 7"
     ]
    }
   ],
   "source": [
    "action=actions[0]\n",
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     env\u001b[39m.\u001b[39msim\u001b[39m.\u001b[39mforward()\n\u001b[1;32m      5\u001b[0m     \u001b[39m# env.render() \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     frame\u001b[39m=\u001b[39menv\u001b[39m.\u001b[39;49mrender(mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrgb_array\u001b[39;49m\u001b[39m\"\u001b[39;49m, height\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, width\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, camera_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfrontview\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m     writer\u001b[39m.\u001b[39mappend_data(frame) \n\u001b[1;32m      9\u001b[0m writer\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mTypeError\u001b[0m: render() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "writer = imageio.get_writer(f\"{ep}_playback_ns.mp4\", fps=20)\n",
    "for state in states:\n",
    "    env.sim.set_state_from_flattened(state)\n",
    "    env.sim.forward()\n",
    "    # env.render() \n",
    "    frame=env.render(mode=\"rgb_array\", height=512, width=512, camera_name=\"frontview\")\n",
    "    writer.append_data(frame) \n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robosuite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348a79be91914f2ee4a15f6f3a1f1988bff4aa5e8f0f365bc9cd0dcd3a15eb1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
